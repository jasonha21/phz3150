{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over- and under-fitting your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHZ3150 - Spring 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A problem you might encounter while trying to fit your data with models is under- or over- fitting them. In the first case our adopted model is too simple to constrain the data in the second case it is too complex, to the point that even noise in our observations is interpreted as part of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over and underfitting data is bad because:\n",
    "- you don't really get the underlying natural law that your data follow\n",
    "- you cannot use your data and model fitting for predicting other data (Machine Learning applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a random dataset we \"observed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,3,30)\n",
    "y = np.sin(2*x) +  np.random.random(len(x))*0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and let's vizualise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 8, 8 ) )\n",
    "plt.errorbar( x, y, yerr = 0.2 , marker='o', linestyle = 'none')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most basic fits you could do would be a function a * x +b. Does it work here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define our function for the line:\n",
    "def my_fit_function(t, a, b):\n",
    "    \"\"\"fit your data with a straight line\"\"\"\n",
    "    #y = a*t+b\n",
    "    return b + a* t \n",
    "\n",
    "\n",
    "# call curve_fit\n",
    "t2, v2 = curve_fit(my_fit_function, x , y, sigma = np.zeros(len(x))+0.2)\n",
    "\n",
    "#plot your result: \n",
    "plt.figure( figsize = ( 6, 6 ) )\n",
    "\n",
    "plt.errorbar( x, y, yerr = 0.2, marker = 'o', linestyle = 'none', label = 'data')\n",
    "plt.plot( x, my_fit_function( x, *t2), linestyle = '-.', color = 'forestgreen', label ='scipy_fit')\n",
    "plt.xticks( fontsize = 20 )\n",
    "plt.yticks( fontsize = 20 )\n",
    "plt.legend( fontsize = 20 )\n",
    "plt.xlabel('X', fontsize = 24)\n",
    "plt.ylabel('Y', fontsize = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is *a* fit of the data. But, do you think it tells us the whole story? What we have done in this very simple example is that we underfitted the data: we got a fit of our data to a model, but there are clearly a lot of information about the nature of the data that our fit ignores! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try a 7th order polynomial fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fit_pol_function(t,  b, c, d, e, f, g, h):\n",
    "    \"\"\"fit your data with a 7th order polynomial\"\"\"\n",
    "    #y =  b * t + c * t**2 + .... + h * t**7\n",
    "    return  b * t + c * t**2 + d* t**3 + e * t**4  + f * t**5 + g * t**6 + h * t**7\n",
    "#+  \\\n",
    "        #   i * t**8  +  j * t**9  + k * t**10. + l * t**11 + m * t**12+ n * t**13 + \\\n",
    "         #  o * t**14 + p * t**15. + q * t**16.\n",
    "\n",
    "\n",
    "t2b, v2b = curve_fit(my_fit_pol_function, x , y, \n",
    "                        sigma = np.zeros(len(x))+0.2)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.errorbar( x, y, yerr = 0.1, marker = 'o', linestyle = 'none',label='data')\n",
    "plt.plot( x, my_fit_pol_function(x, *t2b), linestyle = '-.', color = 'forestgreen',label ='scipy_fit')\n",
    "\n",
    "plt.xticks( fontsize = 20 )\n",
    "plt.yticks( fontsize = 20 )\n",
    "plt.legend( fontsize = 20 )\n",
    "plt.xlabel( 'X', fontsize = 24 )\n",
    "plt.ylabel( 'Y', fontsize = 24 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit seems improved, better constrained model. Still not perfect though...Would a higher order polynomial work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy, of course, offers a polynomial function, you don't need to make it manually: np.polyfit()\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying to fit 30 points of data with a 29th order polynomial!!!\n",
    "zn = np.polyfit(x, y, 29)  # calculate your coeffs\n",
    "print( zn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.poly1d( zn ) \n",
    "print( z )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure( figsize = ( 8, 8 ) )\n",
    "\n",
    "plt.errorbar( x, y, yerr = 0.2, marker = 'o', linestyle = 'none',label='data')\n",
    "\n",
    "plt.plot( x, z(x) ,linestyle='--',color='red',label ='polyfit')\n",
    "plt.xticks( fontsize = 20 )\n",
    "plt.yticks( fontsize = 20 )\n",
    "plt.legend( fontsize = 20 )\n",
    "plt.xlabel( 'X', fontsize = 24)\n",
    "plt.ylabel( 'Y', fontsize = 24)\n",
    "\n",
    "plt.ylim( -1., 1.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a clear example of: \n",
    "- A: underfitting\n",
    "- B: overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### you can see that the high order polynomial fits the data *very* well. Actually *too* well. It actually fits the noise in the data like it were real features (remember that we put noise on top of our 'real' sinusoidal function). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how can we really tell if a model is under or overfitting our data? The best way is to test in an independent dataset how well our model works. E.g., you have N (>>1) observations use .9N to get your fit and .1N to test if your fit makes sense....\n",
    "\n",
    "### In a way, if your fit makes sense it should also be able to predict the future behavior of your data...(ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a wider model to see the real 'future' behavior\n",
    "x3 = np.append(x, [3.2, 3.6, 3.8] )\n",
    "y3 = np.sin(2*x3) + np.random.random(len(x3))*0.6\n",
    "\n",
    "plt.figure( figsize = ( 6, 6 ) )\n",
    "\n",
    "plt.errorbar( x3, y3, yerr = 0.2, marker = 'o', linestyle = 'none', label = 'data')\n",
    "plt.plot( x3, t2[ 0 ] *x3 + t2 [ 1 ], linestyle = '-.', color = 'forestgreen', label ='scipy_fit')\n",
    "plt.errorbar( [3.2, 3.6, 3.8] , y3[ len(x3)-3:  ], yerr = 0.2, marker = 'o', linestyle = 'none', color = 'red' )\n",
    "\n",
    "plt.xticks( fontsize = 20 )\n",
    "plt.yticks( fontsize = 20 )\n",
    "plt.legend( fontsize = 20 )\n",
    "plt.xlabel('X', fontsize = 24)\n",
    "plt.ylabel('Y', fontsize = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand its behavior up to x = 4\n",
    "qq =  t2b[ 0 ] * x3 + t2b[ 1 ] * x3**2 + t2b[ 2 ]* x3**3 + \\\n",
    "     t2b[ 3 ] * x3**4  + t2b[ 4 ] * x3**5 +  t2b[ 5 ] * x3**6  +  t2b[ 6 ] * x3**7    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a wider model to see the real 'future' behavior and overplot the higher order polynomial:\n",
    "plt.figure( figsize = ( 12, 12 ) )\n",
    "\n",
    "plt.errorbar( x3, y3, yerr = 0.2, marker = 'o', linestyle = 'none', label = 'data')\n",
    "plt.plot( x3, qq  , linestyle = '-.', color = 'forestgreen', label ='scipy_fit')\n",
    "plt.errorbar( [3.2, 3.6, 3.8] , y3[ len(x3)-3:  ], yerr = 0.2, marker = 'o', linestyle = 'none', color = 'red' )\n",
    "\n",
    "plt.xticks( fontsize = 20 )\n",
    "plt.yticks( fontsize = 20 )\n",
    "plt.legend( fontsize = 20 )\n",
    "plt.ylim( -1., 2.5)\n",
    "plt.xlabel('X', fontsize = 24)\n",
    "plt.ylabel('Y', fontsize = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to the 29th deg polynomial;\n",
    "# make a wider model to see the real 'future' behavior and overplot the higher order polynomial:\n",
    "plt.figure( figsize = ( 12, 12 ) )\n",
    "\n",
    "plt.errorbar( x3, y3, yerr = 0.2, marker = 'o', linestyle = 'none', label = 'data')\n",
    "plt.plot( x3, z(x3) , linestyle = '-.', color = 'forestgreen', label ='scipy_fit')\n",
    "plt.errorbar( [3.2, 3.6, 3.8] , y3[ len(x3)-3:  ], yerr = 0.2, marker = 'o', linestyle = 'none', color = 'red' )\n",
    "\n",
    "plt.xticks( fontsize = 20 )\n",
    "plt.yticks( fontsize = 20 )\n",
    "plt.legend( fontsize = 20 )\n",
    "plt.ylim( -2., 2.5)\n",
    "plt.xlabel('X', fontsize = 24)\n",
    "plt.ylabel('Y', fontsize = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your model underfits your data when the model doesn't fit well the data. The model is unable to capture the relationship between the input examples x and the target values y  --> you use a too simplified model to describe what actually happens\n",
    "\n",
    "### Your model overfits your data when it fits them a bit 'too' well....your model is too complex for the few data points you have and it is memorizing all the data, including their noise, as model inputs...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in ML (you can go back to see the guest lecture by M. Himes) you try to figure out if you under- or over-fit your data by minimizing your cost function; a measure of how close your predicted values f(x) are to the real observed y points (a form of cost function is e.g. chi-square minimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in training and validation/testing dataset --> train on one, test and validate on others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you underfit your training dataset in ML your fit will be poor even for your training dataset; if you overfit your fit will be good for the training dataset but will be bad for fitting your testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you do if you find out you under or overfit your data? Multiple things could be the problem:\n",
    "- not enough training data for your model\n",
    "- not accurate enough model, or more often, too complex model \n",
    "- sometimes, especially when ML is at hand, maybe you just have not captured enough observations for *all* your parameters (same true for MCMC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are some cases where your fit can be horrible, but more parameters in your model only increase your fit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.linspace(0, 6, 100)*np.pi\n",
    "y2 = np.cos(x2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = 1 - x2**2/np.math.factorial(2) + x2**4/np.math.factorial(4) \n",
    "\n",
    "z2b = 1 - x2**2/np.math.factorial(2) + x2**4/np.math.factorial(4) - x2**6/np.math.factorial(6) +\\\n",
    "     x2**8/np.math.factorial(8) \n",
    "\n",
    "z2c = 1 - x2**2/np.math.factorial(2) + x2**4/np.math.factorial(4) - x2**6/np.math.factorial(6) +\\\n",
    "     x2**8/np.math.factorial(8) - x2**10/np.math.factorial(10) + x2**12/np.math.factorial(12)\n",
    "\n",
    "z2d = 1 - x2**2/np.math.factorial(2) + x2**4/np.math.factorial(4) - x2**6/np.math.factorial(6) +\\\n",
    "     x2**8/np.math.factorial(8) - x2**10/np.math.factorial(10) + x2**12/np.math.factorial(12) - \\\n",
    "     x2**14/np.math.factorial(14) + x2**16/np.math.factorial(16) - x2**18/np.math.factorial(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 12, 8 ) )\n",
    "plt.plot(x2, y2,   color = 'black', linewidth = 4)\n",
    "plt.plot( x2, z2,  color = 'red')\n",
    "plt.plot( x2, z2b, color = 'blue')\n",
    "plt.plot( x2, z2c, color = 'magenta')\n",
    "plt.plot( x2, z2d, color = 'orange')\n",
    "\n",
    "plt.xlim(0,10)\n",
    "plt.ylim( -2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def func_cos(x, n):\n",
    "    cos_approx = 0\n",
    "    for i in range(n):\n",
    "        coef = (-1)**i\n",
    "        num = x**(2*i)\n",
    "        denom = math.factorial(2*i)\n",
    "        cos_approx += ( coef ) * ( (num)/(denom) )\n",
    "    \n",
    "    return cos_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_rad = (math.radians(145))\n",
    "out = func_cos(angle_rad,5)\n",
    "print(out, np.cos(angle_rad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. We have numpy arrays: \n",
    "x = np.array([0.25,0.5,0.75,1.,1.25,1.5,1.75,2.,2.25,2.5, 2.75,3.,3.25,3.5,3.75,4.0,4.25,4.5,4.75,5.0,5.25] )\n",
    "\n",
    "y = np.array( [ 2.707, 14.667, 7.33, 13.907, 19.583, 28.559, 27.019, 32.177, 59.223, 61.353, 97.764,  \n",
    "               95.65, 118.218, 149.653, 160.158, 195.923, 209.151,276.037, 296.779, 321.571, 400.611 ] )\n",
    "\n",
    "\n",
    "### and error bars: \n",
    "\n",
    "sigma = np.array( [46.654, 80.431, 86.407, 60.667, 89.522, 120.837, 54.983, 72.334, 93.261,\n",
    "                   14.128, 127.621, 121.674, 76.334, 93.644,137.65, 54.396, 51.924, 60.282,\n",
    "                   109.396,125.367, 142.854] )*0.24\n",
    "\n",
    "\n",
    "###  Try to fit the data with a:\n",
    "- linear function $a*x+b$  (use curvefit)\n",
    "- second order polynomial: $a*x^2+b*x +c$ (use curvefit)\n",
    "- third order polynomial: $a*x^3 + b*x^2+c*x +d$ (use curvefit)\n",
    "- sixth order polynomial: $a*x^6 + ...+f*x +g$ (use polyfit)\n",
    "- tenth order polynomial: $a*x^5 +...+ e*x+ f$ (use polyfit)\n",
    "- fifteenth order polynomial: $a*x^{15} +...+ n*x+ o$ (use polyfit)\n",
    "\n",
    "\n",
    "### Which models do you think underfit your data? Which one seem to overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The leap years: Write a function leap_year( t ) that takes as input a year and prints out information on whether it is a leap year or not. \n",
    "\n",
    "- Remember that to be a leap year, the year number must be divisible by four â€“ except for end-of-century years, which must be divisible by 400. So you need to test the following: \n",
    "- any year that is divisible by 400 is a leap year.\n",
    "- Of the remaining years, any year that is divisible by 100 is not a leap year.\n",
    "- Of the remaining years, any year that is divisible by 4 is a leap year.\n",
    "\n",
    "\n",
    "### Test the code out for 1980, 1986, 2000 and 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How many days to the end of the month? Now that you know how to define a leap year make a function that when given a date (day, name of month and year) it will print an informative statement about how many days there are left in the month (so in January 15 2021 it will tell you there are 16 days left, in March 29 2022 it will tell you there are 2 days left etc). Make sure to take into account leap years! \n",
    "\n",
    "### Test the code out for: 12 January 2020, 2 November 2021, 2 February 2020 and 2 February 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's the year 1700 and Ohm hasn't come up with his law yet. In your lab you measured the following data:\n",
    "- Volt =  [  14.0, 142.0 , 34.3, 55.6, 24.2, 84.0, 48.6, 101.2, 154.6, 63.2] \n",
    "- Curr =  [0.333, 3.381, 0.809, 1.309, 0.576, 2.000, 1.157, 2.409, 3.681, 1.504 ]\n",
    "- Volt_err = 2.2\n",
    "- Curr_err = 0.132\n",
    "\n",
    "### Plot your data using an error plot. What is the form that the best-fit model that fits your data should have?\n",
    "### Use Curvefit to find the best-fit resistance of your circuit. Use leastsq to do the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a function that gets as input an ordered numpy array and a number and adds the number in the correct location in the ordered array. Do the same thing, but now with a list. Your functions should NOT use build in functions like sort(), sorted(), np.sort() etc\n",
    "\n",
    "### Test it for array ar1 = np.array( [ 1, 5, 12, 88, 124, 232 ] ) and number n1 = 42 and for lists ar2 = [ 1, 4, 22, 38, 44, 52 ] and n2 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Numbers to words. Make a function num_to_word that gets as input any number up to 999 and prints out its name (so if you give it 42 it will return 'Forty two', if you give it 222 it will return 'Two hundred and twenty two' etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Make a code that asks the user for a filename. Then it checks if a file exists. If so, it let's you know that the file exists. If not it asks the user if they want to make the file (Y/N) and proceeds to do so if the answer is Y.\n",
    "\n",
    "### You can also make the code tell you when the file was created if it is already there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
